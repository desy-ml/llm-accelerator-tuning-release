{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../ares_transverse_tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scienceplots\n",
    "import seaborn as sns\n",
    "from icecream import ic\n",
    "from llm_stats import (\n",
    "    elo_ratings,\n",
    "    hellaswag_scores,\n",
    "    mmlu_scores,\n",
    "    mt_bench_scores,\n",
    "    num_parameters,\n",
    ")\n",
    "from src.eval import Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use([\"science\", \"ieee\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIG_DIR = Path(\"./\")\n",
    "DATA_DIR = Path(\"../../data/paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_names_with_paper_names(ratings_dict: dict) -> None:\n",
    "    ratings_dict[\"GPT 4 Turbo\"] = ratings_dict[\"GPT 4 Turbo Preview\"]\n",
    "    del ratings_dict[\"GPT 4 Turbo Preview\"]\n",
    "    ratings_dict[\"Mistral 7B\"] = ratings_dict[\"Mistral 7B v0.2\"]\n",
    "    del ratings_dict[\"Mistral 7B v0.2\"]\n",
    "    ratings_dict[\"Starling LM 7B\"] = ratings_dict[\"Starling LM 7B Beta\"]\n",
    "    del ratings_dict[\"Starling LM 7B Beta\"]\n",
    "\n",
    "\n",
    "replace_names_with_paper_names(elo_ratings)\n",
    "replace_names_with_paper_names(hellaswag_scores)\n",
    "replace_names_with_paper_names(mmlu_scores)\n",
    "replace_names_with_paper_names(mt_bench_scores)\n",
    "replace_names_with_paper_names(num_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_study = Study.load(\n",
    "    DATA_DIR / \"baselines\" / \"rl\",\n",
    "    runs=\"trial-*_*\",\n",
    "    name=\"Reinforcement learning\",\n",
    "    use_problem_index=True,\n",
    ").head(50)\n",
    "bo_hard_study = Study.load(\n",
    "    DATA_DIR / \"baselines\" / \"bo_hard\",\n",
    "    runs=\"trial-*_*\",\n",
    "    name=\"Bayesian optimisation\",\n",
    "    use_problem_index=True,\n",
    ").head(50)\n",
    "es_study = Study.load(\n",
    "    DATA_DIR / \"baselines\" / \"es\",\n",
    "    runs=\"trial-*_*\",\n",
    "    name=\"Extremum seeking\",\n",
    "    use_problem_index=True,\n",
    ").head(50)\n",
    "random_study = Study.load(\n",
    "    DATA_DIR / \"baselines\" / \"rs\",\n",
    "    runs=\"trial-*_*\",\n",
    "    name=\"Random search\",\n",
    "    use_problem_index=True,\n",
    ").head(50)\n",
    "do_nothing_study = Study.load(\n",
    "    DATA_DIR / \"baselines\" / \"dn\",\n",
    "    runs=\"trial-*_*\",\n",
    "    name=\"Do nothing\",\n",
    "    use_problem_index=True,\n",
    ").head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_studies = [rl_study, bo_hard_study, es_study, random_study, do_nothing_study]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \" - head\" suffixes introduced when taking the studies' heads\n",
    "for study in baseline_studies:\n",
    "    study.name = study.name.replace(\" - head\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_2b_tuning_study = Study.load(\n",
    "    DATA_DIR / \"tuning\" / \"gemma-2b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Gemma 2B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "gpt_4_turbo_tuning_study = Study.load(\n",
    "    DATA_DIR / \"tuning\" / \"gpt-4-0125-preview\",  # Turbo Preview\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"GPT 4 Turbo\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "mixtral_8x7b_tuning_study = Study.load(\n",
    "    DATA_DIR / \"tuning\" / \"mixtral-8x7b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Mixtral 8x7B\",\n",
    "    use_problem_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_llm_studies = [\n",
    "    gemma_2b_tuning_study,\n",
    "    gpt_4_turbo_tuning_study,\n",
    "    mixtral_8x7b_tuning_study,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_2b_explained_study = Study.load(\n",
    "    DATA_DIR / \"explained\" / \"gemma-2b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Gemma 2B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "gemma_7b_explained_study = Study.load(\n",
    "    DATA_DIR / \"explained\" / \"gemma-7b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Gemma 7B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "gpt_35_turbo_explained_study = Study.load(\n",
    "    DATA_DIR / \"explained\" / \"gpt-3.5-turbo-0125\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"GPT 3.5 Turbo\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "gpt_4_explained_study = Study.load(\n",
    "    DATA_DIR / \"explained\" / \"gpt-4\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"GPT 4\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "gpt_4_turbo_explained_study = Study.load(\n",
    "    DATA_DIR / \"explained\" / \"gpt-4-turbo-preview\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"GPT 4 Turbo\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "llama2_7b_explained_study = Study.load(\n",
    "    DATA_DIR / \"explained\" / \"llama2-7b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Llama 2 7B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "llama2_13b_explained_study = Study.load(\n",
    "    DATA_DIR / \"explained\" / \"llama2-13b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Llama 2 13B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "llama2_70b_explained_study = Study.load(\n",
    "    DATA_DIR / \"explained\" / \"llama2-70b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Llama 2 70B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "mistral_7b_v02_explained_study = Study.load(\n",
    "    DATA_DIR / \"explained\" / \"mistral-v0.2\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Mistral 7B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "mixtral_8x7b_explained_study = Study.load(\n",
    "    DATA_DIR / \"explained\" / \"mixtral-8x7b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Mixtral 8x7B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "orca2_7b_explained_study = Study.load(\n",
    "    DATA_DIR / \"explained\" / \"orca2-7b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Orca 2 7B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "orca2_13b_explained_study = Study.load(\n",
    "    DATA_DIR / \"explained\" / \"orca2-13b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Orca 2 13B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "starling_lm_7b_beta_explained_study = Study.load(\n",
    "    DATA_DIR / \"explained\" / \"starling-lm-7b-beta\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Starling LM 7B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "vicuna_7b_16k_explained_study = Study.load(\n",
    "    DATA_DIR / \"explained\" / \"vicuna-7b-16k\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Vicuna 7B 16K\",\n",
    "    use_problem_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_llm_studies = [\n",
    "    gemma_2b_explained_study,\n",
    "    gemma_7b_explained_study,\n",
    "    gpt_35_turbo_explained_study,\n",
    "    gpt_4_explained_study,\n",
    "    gpt_4_turbo_explained_study,\n",
    "    llama2_7b_explained_study,\n",
    "    llama2_13b_explained_study,\n",
    "    llama2_70b_explained_study,\n",
    "    mistral_7b_v02_explained_study,\n",
    "    mixtral_8x7b_explained_study,\n",
    "    orca2_7b_explained_study,\n",
    "    orca2_13b_explained_study,\n",
    "    starling_lm_7b_beta_explained_study,\n",
    "    vicuna_7b_16k_explained_study,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_2b_cot_study = Study.load(\n",
    "    DATA_DIR / \"cot\" / \"gemma-2b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Gemma 2B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "gpt_4_turbo_cot_study = Study.load(\n",
    "    DATA_DIR / \"cot\" / \"gpt-4-0125-preview\",  # Turbo Preview\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"GPT 4 Turbo\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "mixtral_8x7b_cot_study = Study.load(\n",
    "    DATA_DIR / \"cot\" / \"mixtral-8x7b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Mixtral 8x7B\",\n",
    "    use_problem_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_llm_studies = [gemma_2b_cot_study, gpt_4_turbo_cot_study, mixtral_8x7b_cot_study]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_2b_optimization_study = Study.load(\n",
    "    DATA_DIR / \"optimisation\" / \"gemma-2b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Gemma 2B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "gemma_7b_optimization_study = Study.load(\n",
    "    DATA_DIR / \"optimisation\" / \"gemma-7b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Gemma 7B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "gpt_35_turbo_optimization_study = Study.load(\n",
    "    DATA_DIR / \"optimisation\" / \"gpt-3.5-turbo-0125\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"GPT 3.5 Turbo\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "gpt_4_optimization_study = Study.load(\n",
    "    DATA_DIR / \"optimisation\" / \"gpt-4\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"GPT 4\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "gpt_4_turbo_optimization_study = Study.load(\n",
    "    DATA_DIR / \"optimisation\" / \"gpt-4-0125-preview\",  # Turbo Preview\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"GPT 4 Turbo\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "llama2_7b_optimization_study = Study.load(\n",
    "    DATA_DIR / \"optimisation\" / \"llama2-7b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Llama 2 7B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "llama2_13b_optimization_study = Study.load(\n",
    "    DATA_DIR / \"optimisation\" / \"llama2-13b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Llama 2 13B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "llama2_70b_optimization_study = Study.load(\n",
    "    DATA_DIR / \"optimisation\" / \"llama2-70b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Llama 2 70B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "mistral_7b_v02_optimization_study = Study.load(\n",
    "    DATA_DIR / \"optimisation\" / \"mistral-v0.2\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Mistral 7B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "mixtral_8x7b_optimization_study = Study.load(\n",
    "    DATA_DIR / \"optimisation\" / \"mixtral-8x7b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Mixtral 8x7B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "orca2_7b_optimization_study = Study.load(\n",
    "    DATA_DIR / \"optimisation\" / \"orca2-7b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Orca 2 7B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "orca2_13b_optimization_study = Study.load(\n",
    "    DATA_DIR / \"optimisation\" / \"orca2-13b\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Orca 2 13B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "starling_lm_7b_beta_optimization_study = Study.load(\n",
    "    DATA_DIR / \"optimisation\" / \"starling-lm-7b-beta\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Starling LM 7B\",\n",
    "    use_problem_index=True,\n",
    ")\n",
    "vicuna_7b_16k_optimization_study = Study.load(\n",
    "    DATA_DIR / \"optimisation\" / \"vicuna-7b-16k\",\n",
    "    runs=\"trial-*_*/recorded_episodes\",\n",
    "    name=\"Vicuna 7B 16K\",\n",
    "    use_problem_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_llm_studies = [\n",
    "    gemma_2b_optimization_study,\n",
    "    gemma_7b_optimization_study,\n",
    "    gpt_35_turbo_optimization_study,\n",
    "    gpt_4_optimization_study,\n",
    "    gpt_4_turbo_optimization_study,\n",
    "    llama2_7b_optimization_study,\n",
    "    llama2_13b_optimization_study,\n",
    "    llama2_70b_optimization_study,\n",
    "    mistral_7b_v02_optimization_study,\n",
    "    mixtral_8x7b_optimization_study,\n",
    "    orca2_7b_optimization_study,\n",
    "    orca2_13b_optimization_study,\n",
    "    starling_lm_7b_beta_optimization_study,\n",
    "    vicuna_7b_16k_optimization_study,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_studies = (\n",
    "    baseline_studies\n",
    "    + tuning_llm_studies\n",
    "    + explained_llm_studies\n",
    "    + cot_llm_studies\n",
    "    + optimization_llm_studies\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame\n",
    "multi_columns = pd.MultiIndex(\n",
    "    levels=[\n",
    "        [\n",
    "            \"Final MAE\",\n",
    "            \"Normalised MAE improvement\",\n",
    "            \"Normalised accumulated MAE\",\n",
    "            \"Number of steps\",\n",
    "        ],\n",
    "        [\"Tuning\", \"Explained\", \"CoT\", \"Optimsation\", \"None\"],\n",
    "        [\"Mean\", \"Std\"],\n",
    "    ],\n",
    "    codes=[[], [], []],\n",
    "    names=[\"Metric\", \"Prompt\", \"Statistic\"],\n",
    ")\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(columns=multi_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final MAE\n",
    "for study in baseline_studies:\n",
    "    df.loc[study.name, (\"Final MAE\", \"None\", \"Mean\")] = study.mean_final_mae()\n",
    "    df.loc[study.name, (\"Final MAE\", \"None\", \"Std\")] = study.std_final_mae()\n",
    "\n",
    "for study in tuning_llm_studies:\n",
    "    df.loc[study.name, (\"Final MAE\", \"Tuning\", \"Mean\")] = study.mean_final_mae()\n",
    "    df.loc[study.name, (\"Final MAE\", \"Tuning\", \"Std\")] = study.std_final_mae()\n",
    "\n",
    "for study in explained_llm_studies:\n",
    "    df.loc[study.name, (\"Final MAE\", \"Explained\", \"Mean\")] = study.mean_final_mae()\n",
    "    df.loc[study.name, (\"Final MAE\", \"Explained\", \"Std\")] = study.std_final_mae()\n",
    "\n",
    "for study in cot_llm_studies:\n",
    "    df.loc[study.name, (\"Final MAE\", \"CoT\", \"Mean\")] = study.mean_final_mae()\n",
    "    df.loc[study.name, (\"Final MAE\", \"CoT\", \"Std\")] = study.std_final_mae()\n",
    "\n",
    "for study in optimization_llm_studies:\n",
    "    df.loc[study.name, (\"Final MAE\", \"Optimsation\", \"Mean\")] = study.mean_final_mae()\n",
    "    df.loc[study.name, (\"Final MAE\", \"Optimsation\", \"Std\")] = study.std_final_mae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised MAE improvement\n",
    "for study in baseline_studies:\n",
    "    collected_normalised_mae_improvements = []\n",
    "    for episode in study.episodes:\n",
    "        do_nothing_episode = do_nothing_study.get_episodes_by_problem(\n",
    "            episode.problem_index\n",
    "        )[0]\n",
    "        collected_normalised_mae_improvements.append(\n",
    "            (episode.final_mae() - do_nothing_episode.maes()[0])\n",
    "            / do_nothing_episode.maes()[0]\n",
    "        )\n",
    "\n",
    "    df.loc[study.name, (\"Normalised MAE improvement\", \"None\", \"Mean\")] = np.mean(\n",
    "        collected_normalised_mae_improvements\n",
    "    )\n",
    "    df.loc[study.name, (\"Normalised MAE improvement\", \"None\", \"Std\")] = np.std(\n",
    "        collected_normalised_mae_improvements\n",
    "    )\n",
    "\n",
    "for study in tuning_llm_studies:\n",
    "    collected_normalised_mae_improvements = []\n",
    "    for episode in study.episodes:\n",
    "        do_nothing_episode = do_nothing_study.get_episodes_by_problem(\n",
    "            episode.problem_index\n",
    "        )[0]\n",
    "        collected_normalised_mae_improvements.append(\n",
    "            (episode.final_mae() - do_nothing_episode.maes()[0])\n",
    "            / do_nothing_episode.maes()[0]\n",
    "        )\n",
    "\n",
    "    df.loc[study.name, (\"Normalised MAE improvement\", \"Tuning\", \"Mean\")] = np.mean(\n",
    "        collected_normalised_mae_improvements\n",
    "    )\n",
    "    df.loc[study.name, (\"Normalised MAE improvement\", \"Tuning\", \"Std\")] = np.std(\n",
    "        collected_normalised_mae_improvements\n",
    "    )\n",
    "\n",
    "for study in explained_llm_studies:\n",
    "    collected_normalised_mae_improvements = []\n",
    "    for episode in study.episodes:\n",
    "        do_nothing_episode = do_nothing_study.get_episodes_by_problem(\n",
    "            episode.problem_index\n",
    "        )[0]\n",
    "        collected_normalised_mae_improvements.append(\n",
    "            (episode.final_mae() - do_nothing_episode.maes()[0])\n",
    "            / do_nothing_episode.maes()[0]\n",
    "        )\n",
    "\n",
    "    df.loc[study.name, (\"Normalised MAE improvement\", \"Explained\", \"Mean\")] = np.mean(\n",
    "        collected_normalised_mae_improvements\n",
    "    )\n",
    "    df.loc[study.name, (\"Normalised MAE improvement\", \"Explained\", \"Std\")] = np.std(\n",
    "        collected_normalised_mae_improvements\n",
    "    )\n",
    "\n",
    "for study in cot_llm_studies:\n",
    "    collected_normalised_mae_improvements = []\n",
    "    for episode in study.episodes:\n",
    "        do_nothing_episode = do_nothing_study.get_episodes_by_problem(\n",
    "            episode.problem_index\n",
    "        )[0]\n",
    "        collected_normalised_mae_improvements.append(\n",
    "            (episode.final_mae() - do_nothing_episode.maes()[0])\n",
    "            / do_nothing_episode.maes()[0]\n",
    "        )\n",
    "\n",
    "    df.loc[study.name, (\"Normalised MAE improvement\", \"CoT\", \"Mean\")] = np.mean(\n",
    "        collected_normalised_mae_improvements\n",
    "    )\n",
    "    df.loc[study.name, (\"Normalised MAE improvement\", \"CoT\", \"Std\")] = np.std(\n",
    "        collected_normalised_mae_improvements\n",
    "    )\n",
    "\n",
    "for study in optimization_llm_studies:\n",
    "    collected_normalised_mae_improvements = []\n",
    "    for episode in study.episodes:\n",
    "        do_nothing_episode = do_nothing_study.get_episodes_by_problem(\n",
    "            episode.problem_index\n",
    "        )[0]\n",
    "        collected_normalised_mae_improvements.append(\n",
    "            (episode.final_mae() - do_nothing_episode.maes()[0])\n",
    "            / do_nothing_episode.maes()[0]\n",
    "        )\n",
    "\n",
    "    df.loc[study.name, (\"Normalised MAE improvement\", \"Optimsation\", \"Mean\")] = np.mean(\n",
    "        collected_normalised_mae_improvements\n",
    "    )\n",
    "    df.loc[study.name, (\"Normalised MAE improvement\", \"Optimsation\", \"Std\")] = np.std(\n",
    "        collected_normalised_mae_improvements\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised accumulated MAE\n",
    "for study in baseline_studies:\n",
    "    collected_normalised_accumulated_maes = []\n",
    "    for episode in study.episodes:\n",
    "        do_nothing_episode = do_nothing_study.get_episodes_by_problem(\n",
    "            episode.problem_index\n",
    "        )[0]\n",
    "        collected_normalised_accumulated_maes.append(\n",
    "            episode.accumulated_mae() / do_nothing_episode.accumulated_mae()\n",
    "        )\n",
    "\n",
    "    df.loc[study.name, (\"Normalised accumulated MAE\", \"None\", \"Mean\")] = np.mean(\n",
    "        collected_normalised_accumulated_maes\n",
    "    )\n",
    "    df.loc[study.name, (\"Normalised accumulated MAE\", \"None\", \"Std\")] = np.std(\n",
    "        collected_normalised_accumulated_maes\n",
    "    )\n",
    "\n",
    "for study in tuning_llm_studies:\n",
    "    collected_normalised_accumulated_maes = []\n",
    "    for episode in study.episodes:\n",
    "        do_nothing_episode = do_nothing_study.get_episodes_by_problem(\n",
    "            episode.problem_index\n",
    "        )[0]\n",
    "        collected_normalised_accumulated_maes.append(\n",
    "            episode.accumulated_mae() / do_nothing_episode.accumulated_mae()\n",
    "        )\n",
    "\n",
    "    df.loc[study.name, (\"Normalised accumulated MAE\", \"Tuning\", \"Mean\")] = np.mean(\n",
    "        collected_normalised_accumulated_maes\n",
    "    )\n",
    "    df.loc[study.name, (\"Normalised accumulated MAE\", \"Tuning\", \"Std\")] = np.std(\n",
    "        collected_normalised_accumulated_maes\n",
    "    )\n",
    "\n",
    "for study in explained_llm_studies:\n",
    "    collected_normalised_accumulated_maes = []\n",
    "    for episode in study.episodes:\n",
    "        do_nothing_episode = do_nothing_study.get_episodes_by_problem(\n",
    "            episode.problem_index\n",
    "        )[0]\n",
    "        collected_normalised_accumulated_maes.append(\n",
    "            episode.accumulated_mae() / do_nothing_episode.accumulated_mae()\n",
    "        )\n",
    "\n",
    "    df.loc[study.name, (\"Normalised accumulated MAE\", \"Explained\", \"Mean\")] = np.mean(\n",
    "        collected_normalised_accumulated_maes\n",
    "    )\n",
    "    df.loc[study.name, (\"Normalised accumulated MAE\", \"Explained\", \"Std\")] = np.std(\n",
    "        collected_normalised_accumulated_maes\n",
    "    )\n",
    "\n",
    "for study in cot_llm_studies:\n",
    "    collected_normalised_accumulated_maes = []\n",
    "    for episode in study.episodes:\n",
    "        do_nothing_episode = do_nothing_study.get_episodes_by_problem(\n",
    "            episode.problem_index\n",
    "        )[0]\n",
    "        collected_normalised_accumulated_maes.append(\n",
    "            episode.accumulated_mae() / do_nothing_episode.accumulated_mae()\n",
    "        )\n",
    "\n",
    "    df.loc[study.name, (\"Normalised accumulated MAE\", \"CoT\", \"Mean\")] = np.mean(\n",
    "        collected_normalised_accumulated_maes\n",
    "    )\n",
    "    df.loc[study.name, (\"Normalised accumulated MAE\", \"CoT\", \"Std\")] = np.std(\n",
    "        collected_normalised_accumulated_maes\n",
    "    )\n",
    "\n",
    "for study in optimization_llm_studies:\n",
    "    collected_normalised_accumulated_maes = []\n",
    "    for episode in study.episodes:\n",
    "        do_nothing_episode = do_nothing_study.get_episodes_by_problem(\n",
    "            episode.problem_index\n",
    "        )[0]\n",
    "        collected_normalised_accumulated_maes.append(\n",
    "            episode.accumulated_mae() / do_nothing_episode.accumulated_mae()\n",
    "        )\n",
    "\n",
    "    df.loc[study.name, (\"Normalised accumulated MAE\", \"Optimsation\", \"Mean\")] = np.mean(\n",
    "        collected_normalised_accumulated_maes\n",
    "    )\n",
    "    df.loc[study.name, (\"Normalised accumulated MAE\", \"Optimsation\", \"Std\")] = np.std(\n",
    "        collected_normalised_accumulated_maes\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of steps\n",
    "for study in tuning_llm_studies:\n",
    "    collected_steps = []\n",
    "    for episode in study.episodes:\n",
    "        collected_steps.append(len(episode) - 1)  # -1 to not count reset\n",
    "\n",
    "    df.loc[study.name, (\"Number of steps\", \"Tuning\", \"Mean\")] = np.mean(collected_steps)\n",
    "    df.loc[study.name, (\"Number of steps\", \"Tuning\", \"Std\")] = np.std(collected_steps)\n",
    "\n",
    "for study in explained_llm_studies:\n",
    "    collected_steps = []\n",
    "    for episode in study.episodes:\n",
    "        collected_steps.append(len(episode) - 1)  # -1 to not count reset\n",
    "\n",
    "    df.loc[study.name, (\"Number of steps\", \"Explained\", \"Mean\")] = np.mean(\n",
    "        collected_steps\n",
    "    )\n",
    "    df.loc[study.name, (\"Number of steps\", \"Explained\", \"Std\")] = np.std(\n",
    "        collected_steps\n",
    "    )\n",
    "\n",
    "for study in cot_llm_studies:\n",
    "    collected_steps = []\n",
    "    for episode in study.episodes:\n",
    "        collected_steps.append(len(episode) - 1)  # -1 to not count reset\n",
    "\n",
    "    df.loc[study.name, (\"Number of steps\", \"CoT\", \"Mean\")] = np.mean(collected_steps)\n",
    "    df.loc[study.name, (\"Number of steps\", \"CoT\", \"Std\")] = np.std(collected_steps)\n",
    "\n",
    "for study in optimization_llm_studies:\n",
    "    collected_steps = []\n",
    "    for episode in study.episodes:\n",
    "        collected_steps.append(len(episode) - 1)  # -1 to not count reset\n",
    "\n",
    "    df.loc[study.name, (\"Number of steps\", \"Optimsation\", \"Mean\")] = np.mean(\n",
    "        collected_steps\n",
    "    )\n",
    "    df.loc[study.name, (\"Number of steps\", \"Optimsation\", \"Std\")] = np.std(\n",
    "        collected_steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, (\"Final MAE (mum)\", \"None\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Final MAE\", \"None\", \"Mean\")] * 1e6\n",
    ").round()\n",
    "df.loc[:, (\"Final MAE (mum)\", \"None\", \"Std\")] = (\n",
    "    df.loc[:, (\"Final MAE\", \"None\", \"Std\")] * 1e6\n",
    ").round()\n",
    "df.loc[:, (\"Final MAE (mum)\", \"Tuning\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Final MAE\", \"Tuning\", \"Mean\")] * 1e6\n",
    ").round()\n",
    "df.loc[:, (\"Final MAE (mum)\", \"Tuning\", \"Std\")] = (\n",
    "    df.loc[:, (\"Final MAE\", \"Tuning\", \"Std\")] * 1e6\n",
    ").round()\n",
    "df.loc[:, (\"Final MAE (mum)\", \"Explained\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Final MAE\", \"Explained\", \"Mean\")] * 1e6\n",
    ").round()\n",
    "df.loc[:, (\"Final MAE (mum)\", \"Explained\", \"Std\")] = (\n",
    "    df.loc[:, (\"Final MAE\", \"Explained\", \"Std\")] * 1e6\n",
    ").round()\n",
    "df.loc[:, (\"Final MAE (mum)\", \"CoT\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Final MAE\", \"CoT\", \"Mean\")] * 1e6\n",
    ").round()\n",
    "df.loc[:, (\"Final MAE (mum)\", \"CoT\", \"Std\")] = (\n",
    "    df.loc[:, (\"Final MAE\", \"CoT\", \"Std\")] * 1e6\n",
    ").round()\n",
    "df.loc[:, (\"Final MAE (mum)\", \"Optimsation\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Final MAE\", \"Optimsation\", \"Mean\")] * 1e6\n",
    ").round()\n",
    "df.loc[:, (\"Final MAE (mum)\", \"Optimsation\", \"Std\")] = (\n",
    "    df.loc[:, (\"Final MAE\", \"Optimsation\", \"Std\")] * 1e6\n",
    ").round()\n",
    "\n",
    "df = df.drop(columns=[\"Final MAE\"])\n",
    "\n",
    "df.loc[:, (\"Normalised MAE improvement (%)\", \"None\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Normalised MAE improvement\", \"None\", \"Mean\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised MAE improvement (%)\", \"None\", \"Std\")] = (\n",
    "    df.loc[:, (\"Normalised MAE improvement\", \"None\", \"Std\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised MAE improvement (%)\", \"Tuning\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Normalised MAE improvement\", \"Tuning\", \"Mean\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised MAE improvement (%)\", \"Tuning\", \"Std\")] = (\n",
    "    df.loc[:, (\"Normalised MAE improvement\", \"Tuning\", \"Std\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised MAE improvement (%)\", \"Explained\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Normalised MAE improvement\", \"Explained\", \"Mean\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised MAE improvement (%)\", \"Explained\", \"Std\")] = (\n",
    "    df.loc[:, (\"Normalised MAE improvement\", \"Explained\", \"Std\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised MAE improvement (%)\", \"CoT\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Normalised MAE improvement\", \"CoT\", \"Mean\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised MAE improvement (%)\", \"CoT\", \"Std\")] = (\n",
    "    df.loc[:, (\"Normalised MAE improvement\", \"CoT\", \"Std\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised MAE improvement (%)\", \"Optimsation\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Normalised MAE improvement\", \"Optimsation\", \"Mean\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised MAE improvement (%)\", \"Optimsation\", \"Std\")] = (\n",
    "    df.loc[:, (\"Normalised MAE improvement\", \"Optimsation\", \"Std\")] * 100\n",
    ").round()\n",
    "\n",
    "df = df.drop(columns=[\"Normalised MAE improvement\"])\n",
    "\n",
    "df.loc[:, (\"Normalised accumulated MAE (%)\", \"None\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Normalised accumulated MAE\", \"None\", \"Mean\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised accumulated MAE (%)\", \"None\", \"Std\")] = (\n",
    "    df.loc[:, (\"Normalised accumulated MAE\", \"None\", \"Std\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised accumulated MAE (%)\", \"Tuning\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Normalised accumulated MAE\", \"Tuning\", \"Mean\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised accumulated MAE (%)\", \"Tuning\", \"Std\")] = (\n",
    "    df.loc[:, (\"Normalised accumulated MAE\", \"Tuning\", \"Std\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised accumulated MAE (%)\", \"Explained\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Normalised accumulated MAE\", \"Explained\", \"Mean\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised accumulated MAE (%)\", \"Explained\", \"Std\")] = (\n",
    "    df.loc[:, (\"Normalised accumulated MAE\", \"Explained\", \"Std\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised accumulated MAE (%)\", \"CoT\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Normalised accumulated MAE\", \"CoT\", \"Mean\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised accumulated MAE (%)\", \"CoT\", \"Std\")] = (\n",
    "    df.loc[:, (\"Normalised accumulated MAE\", \"CoT\", \"Std\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised accumulated MAE (%)\", \"Optimsation\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Normalised accumulated MAE\", \"Optimsation\", \"Mean\")] * 100\n",
    ").round()\n",
    "df.loc[:, (\"Normalised accumulated MAE (%)\", \"Optimsation\", \"Std\")] = (\n",
    "    df.loc[:, (\"Normalised accumulated MAE\", \"Optimsation\", \"Std\")] * 100\n",
    ").round()\n",
    "\n",
    "df = df.drop(columns=[\"Normalised accumulated MAE\"])\n",
    "\n",
    "df.loc[:, (\"Number of steps\", \"Tuning\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Number of steps\", \"Tuning\", \"Mean\")]\n",
    ").round()\n",
    "df.loc[:, (\"Number of steps\", \"Tuning\", \"Std\")] = (\n",
    "    df.loc[:, (\"Number of steps\", \"Tuning\", \"Std\")]\n",
    ").round()\n",
    "df.loc[:, (\"Number of steps\", \"Explained\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Number of steps\", \"Explained\", \"Mean\")]\n",
    ").round()\n",
    "df.loc[:, (\"Number of steps\", \"Explained\", \"Std\")] = (\n",
    "    df.loc[:, (\"Number of steps\", \"Explained\", \"Std\")]\n",
    ").round()\n",
    "df.loc[:, (\"Number of steps\", \"CoT\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Number of steps\", \"CoT\", \"Mean\")]\n",
    ").round()\n",
    "df.loc[:, (\"Number of steps\", \"CoT\", \"Std\")] = (\n",
    "    df.loc[:, (\"Number of steps\", \"CoT\", \"Std\")]\n",
    ").round()\n",
    "df.loc[:, (\"Number of steps\", \"Optimsation\", \"Mean\")] = (\n",
    "    df.loc[:, (\"Number of steps\", \"Optimsation\", \"Mean\")]\n",
    ").round()\n",
    "df.loc[:, (\"Number of steps\", \"Optimsation\", \"Std\")] = (\n",
    "    df.loc[:, (\"Number of steps\", \"Optimsation\", \"Std\")]\n",
    ").round()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_multi_columns = pd.MultiIndex(\n",
    "    levels=[\n",
    "        [\n",
    "            \"Final MAE (mum)\",\n",
    "            \"Normalised MAE improvement (%)\",\n",
    "            \"Normalised accumulated MAE (%)\",\n",
    "        ],\n",
    "        [\"Tuning\", \"Explained\", \"CoT\", \"Optimsation\", \"None\"],\n",
    "    ],\n",
    "    codes=[[], []],\n",
    "    names=[\"Metric\", \"Prompt\"],\n",
    ")\n",
    "df_paper = pd.DataFrame(columns=paper_multi_columns)\n",
    "\n",
    "# Combine two columns into a string\n",
    "df_paper.loc[:, (\"Final MAE (mum)\", \"Tuning\")] = (\n",
    "    df.loc[:, (\"Final MAE (mum)\", \"Tuning\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Final MAE (mum)\", \"Tuning\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Final MAE (mum)\", \"Explained\")] = (\n",
    "    df.loc[:, (\"Final MAE (mum)\", \"Explained\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Final MAE (mum)\", \"Explained\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Final MAE (mum)\", \"Optimsation\")] = (\n",
    "    df.loc[:, (\"Final MAE (mum)\", \"Optimsation\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Final MAE (mum)\", \"Optimsation\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Final MAE (mum)\", \"CoT\")] = (\n",
    "    df.loc[:, (\"Final MAE (mum)\", \"CoT\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Final MAE (mum)\", \"CoT\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Final MAE (mum)\", \"None\")] = (\n",
    "    df.loc[:, (\"Final MAE (mum)\", \"None\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Final MAE (mum)\", \"None\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Normalised MAE improvement (%)\", \"Tuning\")] = (\n",
    "    df.loc[:, (\"Normalised MAE improvement (%)\", \"Tuning\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Normalised MAE improvement (%)\", \"Tuning\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Normalised MAE improvement (%)\", \"Explained\")] = (\n",
    "    df.loc[:, (\"Normalised MAE improvement (%)\", \"Explained\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Normalised MAE improvement (%)\", \"Explained\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Normalised MAE improvement (%)\", \"CoT\")] = (\n",
    "    df.loc[:, (\"Normalised MAE improvement (%)\", \"CoT\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Normalised MAE improvement (%)\", \"CoT\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Normalised MAE improvement (%)\", \"Optimsation\")] = (\n",
    "    df.loc[:, (\"Normalised MAE improvement (%)\", \"Optimsation\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Normalised MAE improvement (%)\", \"Optimsation\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Normalised MAE improvement (%)\", \"None\")] = (\n",
    "    df.loc[:, (\"Normalised MAE improvement (%)\", \"None\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Normalised MAE improvement (%)\", \"None\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Normalised accumulated MAE (%)\", \"Tuning\")] = (\n",
    "    df.loc[:, (\"Normalised accumulated MAE (%)\", \"Tuning\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Normalised accumulated MAE (%)\", \"Tuning\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Normalised accumulated MAE (%)\", \"Explained\")] = (\n",
    "    df.loc[:, (\"Normalised accumulated MAE (%)\", \"Explained\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Normalised accumulated MAE (%)\", \"Explained\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Normalised accumulated MAE (%)\", \"CoT\")] = (\n",
    "    df.loc[:, (\"Normalised accumulated MAE (%)\", \"CoT\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Normalised accumulated MAE (%)\", \"CoT\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Normalised accumulated MAE (%)\", \"Optimsation\")] = (\n",
    "    df.loc[:, (\"Normalised accumulated MAE (%)\", \"Optimsation\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Normalised accumulated MAE (%)\", \"Optimsation\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Normalised accumulated MAE (%)\", \"None\")] = (\n",
    "    df.loc[:, (\"Normalised accumulated MAE (%)\", \"None\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Normalised accumulated MAE (%)\", \"None\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Number of steps\", \"Tuning\")] = (\n",
    "    df.loc[:, (\"Number of steps\", \"Tuning\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Number of steps\", \"Tuning\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Number of steps\", \"Explained\")] = (\n",
    "    df.loc[:, (\"Number of steps\", \"Explained\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Number of steps\", \"Explained\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Number of steps\", \"CoT\")] = (\n",
    "    df.loc[:, (\"Number of steps\", \"CoT\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Number of steps\", \"CoT\", \"Std\")].astype(str)\n",
    ")\n",
    "df_paper.loc[:, (\"Number of steps\", \"Optimsation\")] = (\n",
    "    df.loc[:, (\"Number of steps\", \"Optimsation\", \"Mean\")].astype(str)\n",
    "    + \" ± \"\n",
    "    + df.loc[:, (\"Number of steps\", \"Optimsation\", \"Std\")].astype(str)\n",
    ")\n",
    "\n",
    "df_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paper = df_paper.loc[\n",
    "    [\n",
    "        \"Gemma 2B\",\n",
    "        \"Gemma 7B\",\n",
    "        \"GPT 3.5 Turbo\",\n",
    "        \"GPT 4\",\n",
    "        \"GPT 4 Turbo\",\n",
    "        \"Llama 2 7B\",\n",
    "        \"Llama 2 13B\",\n",
    "        \"Llama 2 70B\",\n",
    "        \"Orca 2 7B\",\n",
    "        \"Orca 2 13B\",\n",
    "        \"Vicuna 7B 16K\",\n",
    "        \"Mistral 7B\",\n",
    "        \"Mixtral 8x7B\",\n",
    "        \"Starling LM 7B\",\n",
    "        \"Reinforcement learning\",\n",
    "        \"Bayesian optimisation\",\n",
    "        \"Extremum seeking\",\n",
    "        \"Random search\",\n",
    "        \"Do nothing\",\n",
    "    ]\n",
    "]\n",
    "df_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_paper.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for study in all_studies:\n",
    "    num_successes = 0\n",
    "    for episode in study.episodes:\n",
    "        do_nothing_episode = do_nothing_study.get_episodes_by_problem(\n",
    "            episode.problem_index\n",
    "        )[0]\n",
    "        mae_to_beat = do_nothing_episode.maes()[0]\n",
    "        if episode.final_mae() < mae_to_beat - 40e-6:\n",
    "            num_successes += 1\n",
    "\n",
    "    if study in tuning_llm_studies:\n",
    "        prompt_type = \"-- Tuning --\"\n",
    "    elif study in explained_llm_studies:\n",
    "        prompt_type = \"-- Explained --\"\n",
    "    elif study in optimization_llm_studies:\n",
    "        prompt_type = \"-- Optimisation --\"\n",
    "    elif study in cot_llm_studies:\n",
    "        prompt_type = \"-- Chain-of-thought --\"\n",
    "    else:\n",
    "        prompt_type = \"--\"\n",
    "\n",
    "    print(f\"{study.name} {prompt_type}: {num_successes}/{len(study.episodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successes_df = pd.DataFrame(columns=[\"Tuning\", \"Explained\", \"CoT\", \"Optimisation\"])\n",
    "\n",
    "for explained, optimisation in zip(\n",
    "    explained_llm_studies + baseline_studies,\n",
    "    optimization_llm_studies + baseline_studies,\n",
    "):\n",
    "    for column, study in zip([\"Explained\", \"Optimisation\"], [explained, optimisation]):\n",
    "        num_successes = 0\n",
    "        for episode in study.episodes:\n",
    "            do_nothing_episode = do_nothing_study.get_episodes_by_problem(\n",
    "                episode.problem_index\n",
    "            )[0]\n",
    "            mae_to_beat = do_nothing_episode.maes()[0]\n",
    "            if episode.final_mae() < mae_to_beat - 40e-6:\n",
    "                num_successes += 1\n",
    "\n",
    "            successes_df.loc[study.name, column] = num_successes\n",
    "\n",
    "for tuning, cot in zip(tuning_llm_studies, cot_llm_studies):\n",
    "    for column, study in zip([\"Tuning\", \"CoT\"], [tuning, cot]):\n",
    "        num_successes = 0\n",
    "        for episode in study.episodes:\n",
    "            do_nothing_episode = do_nothing_study.get_episodes_by_problem(\n",
    "                episode.problem_index\n",
    "            )[0]\n",
    "            mae_to_beat = do_nothing_episode.maes()[0]\n",
    "            if episode.final_mae() < mae_to_beat - 40e-6:\n",
    "                num_successes += 1\n",
    "\n",
    "            successes_df.loc[study.name, column] = num_successes\n",
    "\n",
    "# sns.heatmap(df, annot=True, cmap=\"viridis\")\n",
    "successes_df = successes_df.loc[\n",
    "    [\n",
    "        \"Gemma 2B\",\n",
    "        \"Gemma 7B\",\n",
    "        \"GPT 3.5 Turbo\",\n",
    "        \"GPT 4\",\n",
    "        \"GPT 4 Turbo\",\n",
    "        \"Llama 2 7B\",\n",
    "        \"Llama 2 13B\",\n",
    "        \"Llama 2 70B\",\n",
    "        \"Orca 2 7B\",\n",
    "        \"Orca 2 13B\",\n",
    "        \"Vicuna 7B 16K\",\n",
    "        \"Mistral 7B\",\n",
    "        \"Mixtral 8x7B\",\n",
    "        \"Starling LM 7B\",\n",
    "        \"Reinforcement learning\",\n",
    "        \"Bayesian optimisation\",\n",
    "        \"Extremum seeking\",\n",
    "        \"Random search\",\n",
    "        \"Do nothing\",\n",
    "    ]\n",
    "]\n",
    "successes_df[\"Tuning\"] = successes_df[\"Tuning\"].astype(float)\n",
    "successes_df[\"Explained\"] = successes_df[\"Explained\"].astype(float)\n",
    "successes_df[\"CoT\"] = successes_df[\"CoT\"].astype(float)\n",
    "successes_df[\"Optimisation\"] = successes_df[\"Optimisation\"].astype(float)\n",
    "\n",
    "# Plot with diverging colour map\n",
    "# plt.figure(figsize=(3, 5))\n",
    "# ax = sns.heatmap(\n",
    "#     successes_df, annot=True, cmap=\"RdYlGn\", center=6, vmin=0, vmax=9, linewidths=0.5\n",
    "# )\n",
    "# ax.set(xlabel=\"\", ylabel=\"\")\n",
    "# ax.xaxis.tick_top()\n",
    "# ax.minorticks_off()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for study in all_studies:\n",
    "    num_successful_trials = 0\n",
    "    for trial_idx in [0, 33, 38]:\n",
    "        assert len(study.get_episodes_by_problem(trial_idx)) > 0\n",
    "\n",
    "        all_successful = True\n",
    "        for episode in study.get_episodes_by_problem(trial_idx):\n",
    "            do_nothing_episode = do_nothing_study.get_episodes_by_problem(\n",
    "                episode.problem_index\n",
    "            )[0]\n",
    "            mae_to_beat = do_nothing_episode.maes()[0]\n",
    "            if not episode.final_mae() < mae_to_beat - 40e-6:\n",
    "                all_successful = False\n",
    "                break\n",
    "\n",
    "        if all_successful:\n",
    "            num_successful_trials += 1\n",
    "\n",
    "    if study in tuning_llm_studies:\n",
    "        prompt_type = \"-- Tuning --\"\n",
    "    elif study in explained_llm_studies:\n",
    "        prompt_type = \"-- Explained --\"\n",
    "    elif study in cot_llm_studies:\n",
    "        prompt_type = \"-- Chain-of-thought --\"\n",
    "    elif study in optimization_llm_studies:\n",
    "        prompt_type = \"-- Optimisation --\"\n",
    "    else:\n",
    "        prompt_type = \"--\"\n",
    "\n",
    "    print(f\"{study.name} {prompt_type}: {num_successful_trials}/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_trials_df = pd.DataFrame(columns=[\"Explained\", \"Optimisation\"])\n",
    "\n",
    "all_successful_trials = []\n",
    "\n",
    "for explained, optimisation in zip(\n",
    "    explained_llm_studies + baseline_studies,\n",
    "    optimization_llm_studies + baseline_studies,\n",
    "):\n",
    "    for column, study in zip([\"Explained\", \"Optimisation\"], [explained, optimisation]):\n",
    "        num_successful_trials = 0\n",
    "        successful_trials = []\n",
    "        for trial_idx in [0, 33, 38]:\n",
    "            assert len(study.get_episodes_by_problem(trial_idx)) > 0\n",
    "\n",
    "            all_successful = True\n",
    "            for episode in study.get_episodes_by_problem(trial_idx):\n",
    "                do_nothing_episode = do_nothing_study.get_episodes_by_problem(\n",
    "                    episode.problem_index\n",
    "                )[0]\n",
    "                mae_to_beat = do_nothing_episode.maes()[0]\n",
    "                if not episode.final_mae() < mae_to_beat - 40e-6:\n",
    "                    all_successful = False\n",
    "                    break\n",
    "\n",
    "            if all_successful:\n",
    "                num_successful_trials += 1\n",
    "                successful_trials.append(trial_idx)\n",
    "\n",
    "        successful_trials_df.loc[study.name, column] = num_successful_trials\n",
    "        print(f\"{study.name} {column}: {successful_trials}\")\n",
    "        all_successful_trials += successful_trials\n",
    "\n",
    "for tuning, cot in zip(tuning_llm_studies, cot_llm_studies):\n",
    "    for column, study in zip([\"Tuning\", \"CoT\"], [tuning, cot]):\n",
    "        num_successful_trials = 0\n",
    "        successful_trials = []\n",
    "        for trial_idx in [0, 33, 38]:\n",
    "            assert len(study.get_episodes_by_problem(trial_idx)) > 0\n",
    "\n",
    "            all_successful = True\n",
    "            for episode in study.get_episodes_by_problem(trial_idx):\n",
    "                do_nothing_episode = do_nothing_study.get_episodes_by_problem(\n",
    "                    episode.problem_index\n",
    "                )[0]\n",
    "                mae_to_beat = do_nothing_episode.maes()[0]\n",
    "                if not episode.final_mae() < mae_to_beat - 40e-6:\n",
    "                    all_successful = False\n",
    "                    break\n",
    "\n",
    "            if all_successful:\n",
    "                num_successful_trials += 1\n",
    "                successful_trials.append(trial_idx)\n",
    "\n",
    "        successful_trials_df.loc[study.name, column] = num_successful_trials\n",
    "        print(f\"{study.name} {column}: {successful_trials}\")\n",
    "        all_successful_trials += successful_trials\n",
    "\n",
    "successful_trials_df = successful_trials_df.loc[\n",
    "    [\n",
    "        \"Gemma 2B\",\n",
    "        \"Gemma 7B\",\n",
    "        \"GPT 3.5 Turbo\",\n",
    "        \"GPT 4\",\n",
    "        \"GPT 4 Turbo\",\n",
    "        \"Llama 2 7B\",\n",
    "        \"Llama 2 13B\",\n",
    "        \"Llama 2 70B\",\n",
    "        \"Orca 2 7B\",\n",
    "        \"Orca 2 13B\",\n",
    "        \"Vicuna 7B 16K\",\n",
    "        \"Mistral 7B\",\n",
    "        \"Mixtral 8x7B\",\n",
    "        \"Starling LM 7B\",\n",
    "        \"Reinforcement learning\",\n",
    "        \"Bayesian optimisation\",\n",
    "        \"Extremum seeking\",\n",
    "        \"Random search\",\n",
    "        \"Do nothing\",\n",
    "    ]\n",
    "]\n",
    "successful_trials_df[\"Tuning\"] = successful_trials_df[\"Tuning\"].astype(float)\n",
    "successful_trials_df[\"Explained\"] = successful_trials_df[\"Explained\"].astype(float)\n",
    "successful_trials_df[\"CoT\"] = successful_trials_df[\"CoT\"].astype(float)\n",
    "successful_trials_df[\"Optimisation\"] = successful_trials_df[\"Optimisation\"].astype(\n",
    "    float\n",
    ")\n",
    "\n",
    "successful_trials_df = successful_trials_df[\n",
    "    [\"Tuning\", \"Explained\", \"CoT\", \"Optimisation\"]\n",
    "]\n",
    "\n",
    "# Plot with diverging colour map\n",
    "# plt.figure(figsize=(3, 5))\n",
    "# ax = sns.heatmap(\n",
    "#     successful_trials_df,\n",
    "#     annot=True,\n",
    "#     cmap=\"RdYlGn\",\n",
    "#     # center=1,\n",
    "#     vmin=0,\n",
    "#     vmax=3,\n",
    "#     linewidths=0.5,\n",
    "# )\n",
    "# ax.set(xlabel=\"\", ylabel=\"\")\n",
    "# ax.xaxis.tick_top()\n",
    "# ax.minorticks_off()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(6, 4.7), sharey=\"row\", height_ratios=[1, 0.5])\n",
    "\n",
    "cmap = plt.get_cmap(\"RdYlGn\")\n",
    "cmap.set_under(\"white\")\n",
    "\n",
    "sns.heatmap(\n",
    "    successes_df.loc[\n",
    "        (\n",
    "            \"Gemma 2B\",\n",
    "            \"Gemma 7B\",\n",
    "            \"GPT 3.5 Turbo\",\n",
    "            \"GPT 4\",\n",
    "            \"GPT 4 Turbo\",\n",
    "            \"Llama 2 7B\",\n",
    "            \"Llama 2 13B\",\n",
    "            \"Llama 2 70B\",\n",
    "            \"Orca 2 7B\",\n",
    "            \"Orca 2 13B\",\n",
    "            \"Vicuna 7B 16K\",\n",
    "            \"Mistral 7B\",\n",
    "            \"Mixtral 8x7B\",\n",
    "            \"Starling LM 7B\",\n",
    "        ),\n",
    "        :,\n",
    "    ].fillna(-1),\n",
    "    annot=successes_df.loc[\n",
    "        (\n",
    "            \"Gemma 2B\",\n",
    "            \"Gemma 7B\",\n",
    "            \"GPT 3.5 Turbo\",\n",
    "            \"GPT 4\",\n",
    "            \"GPT 4 Turbo\",\n",
    "            \"Llama 2 7B\",\n",
    "            \"Llama 2 13B\",\n",
    "            \"Llama 2 70B\",\n",
    "            \"Orca 2 7B\",\n",
    "            \"Orca 2 13B\",\n",
    "            \"Vicuna 7B 16K\",\n",
    "            \"Mistral 7B\",\n",
    "            \"Mixtral 8x7B\",\n",
    "            \"Starling LM 7B\",\n",
    "        ),\n",
    "        :,\n",
    "    ]\n",
    "    .fillna(-1)\n",
    "    .astype(int)\n",
    "    .astype(str)\n",
    "    .replace(\"-1\", \"-\"),\n",
    "    cmap=cmap,\n",
    "    # center=6,\n",
    "    vmin=0,\n",
    "    vmax=9,\n",
    "    linewidths=0.5,\n",
    "    ax=axs[0, 0],\n",
    "    cbar=False,\n",
    "    fmt=\"\",\n",
    ")\n",
    "axs[0, 0].set(xlabel=\"\", ylabel=\"\")\n",
    "axs[0, 0].xaxis.tick_top()\n",
    "axs[0, 0].tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "axs[0, 0].set_title(\"(a) Successful episodes\")\n",
    "\n",
    "sns.heatmap(\n",
    "    successes_df.loc[\n",
    "        (\n",
    "            \"Reinforcement learning\",\n",
    "            \"Bayesian optimisation\",\n",
    "            \"Extremum seeking\",\n",
    "            \"Random search\",\n",
    "            \"Do nothing\",\n",
    "        ),\n",
    "        (\"Optimisation\",),\n",
    "    ],\n",
    "    annot=True,\n",
    "    cmap=cmap,\n",
    "    # center=6,\n",
    "    vmin=0,\n",
    "    vmax=9,\n",
    "    linewidths=0.5,\n",
    "    ax=axs[1, 0],\n",
    "    cbar_kws={\"location\": \"bottom\", \"ticks\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]},\n",
    ")\n",
    "axs[1, 0].set(xlabel=\"\", ylabel=\"\")\n",
    "axs[1, 0].xaxis.tick_top()\n",
    "axs[1, 0].tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "axs[1, 0].set_xticks([])\n",
    "\n",
    "sns.heatmap(\n",
    "    successful_trials_df.loc[\n",
    "        (\n",
    "            \"Gemma 2B\",\n",
    "            \"Gemma 7B\",\n",
    "            \"GPT 3.5 Turbo\",\n",
    "            \"GPT 4\",\n",
    "            \"GPT 4 Turbo\",\n",
    "            \"Llama 2 7B\",\n",
    "            \"Llama 2 13B\",\n",
    "            \"Llama 2 70B\",\n",
    "            \"Orca 2 7B\",\n",
    "            \"Orca 2 13B\",\n",
    "            \"Vicuna 7B 16K\",\n",
    "            \"Mistral 7B\",\n",
    "            \"Mixtral 8x7B\",\n",
    "            \"Starling LM 7B\",\n",
    "        ),\n",
    "        :,\n",
    "    ].fillna(-1),\n",
    "    annot=successful_trials_df.loc[\n",
    "        (\n",
    "            \"Gemma 2B\",\n",
    "            \"Gemma 7B\",\n",
    "            \"GPT 3.5 Turbo\",\n",
    "            \"GPT 4\",\n",
    "            \"GPT 4 Turbo\",\n",
    "            \"Llama 2 7B\",\n",
    "            \"Llama 2 13B\",\n",
    "            \"Llama 2 70B\",\n",
    "            \"Orca 2 7B\",\n",
    "            \"Orca 2 13B\",\n",
    "            \"Vicuna 7B 16K\",\n",
    "            \"Mistral 7B\",\n",
    "            \"Mixtral 8x7B\",\n",
    "            \"Starling LM 7B\",\n",
    "        ),\n",
    "        :,\n",
    "    ]\n",
    "    .fillna(-1)\n",
    "    .astype(int)\n",
    "    .astype(str)\n",
    "    .replace(\"-1\", \"-\"),\n",
    "    cmap=cmap,\n",
    "    # center=1,\n",
    "    vmin=0,\n",
    "    vmax=3,\n",
    "    linewidths=0.5,\n",
    "    ax=axs[0, 1],\n",
    "    cbar=False,\n",
    "    fmt=\"\",\n",
    ")\n",
    "axs[0, 1].set(xlabel=\"\", ylabel=\"\")\n",
    "axs[0, 1].xaxis.tick_top()\n",
    "axs[0, 1].tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "axs[0, 1].set_title(\"(b) Successful trials\")\n",
    "\n",
    "sns.heatmap(\n",
    "    successful_trials_df.loc[\n",
    "        (\n",
    "            \"Reinforcement learning\",\n",
    "            \"Bayesian optimisation\",\n",
    "            \"Extremum seeking\",\n",
    "            \"Random search\",\n",
    "            \"Do nothing\",\n",
    "        ),\n",
    "        (\"Optimisation\",),\n",
    "    ],\n",
    "    annot=True,\n",
    "    cmap=cmap,\n",
    "    # center=1,\n",
    "    vmin=0,\n",
    "    vmax=3,\n",
    "    linewidths=0.5,\n",
    "    ax=axs[1, 1],\n",
    "    cbar_kws={\"location\": \"bottom\", \"ticks\": [0, 1, 2, 3]},\n",
    ")\n",
    "axs[1, 1].set(xlabel=\"\", ylabel=\"\")\n",
    "axs[1, 1].xaxis.tick_top()\n",
    "axs[1, 1].tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "axs[1, 1].set_xticks([])\n",
    "\n",
    "fig.axes[4].minorticks_off()\n",
    "fig.axes[5].minorticks_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(FIG_DIR / \"success_heatmaps.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how often each trial appears in the all_successful_trials list\n",
    "counter = Counter(all_successful_trials)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_successes_df = successes_df.copy()\n",
    "extended_successes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, elo in elo_ratings.items():\n",
    "    extended_successes_df.loc[name, \"ELO\"] = elo\n",
    "\n",
    "for name, hellaswag in hellaswag_scores.items():\n",
    "    extended_successes_df.loc[name, \"HellaSwag\"] = hellaswag\n",
    "\n",
    "for name, mmlu in mmlu_scores.items():\n",
    "    extended_successes_df.loc[name, \"MMLU\"] = mmlu\n",
    "\n",
    "for name, mt_bench in mt_bench_scores.items():\n",
    "    extended_successes_df.loc[name, \"MT-bench\"] = mt_bench\n",
    "\n",
    "for name, num_param in num_parameters.items():\n",
    "    extended_successes_df.loc[name, \"Num parameters\"] = num_param\n",
    "\n",
    "for name in extended_successes_df.index:\n",
    "    extended_successes_df.loc[name, \"Optimisation Final MAE (mum)\"] = df.loc[\n",
    "        name, (\"Final MAE (mum)\", \"Optimsation\", \"Mean\")\n",
    "    ]\n",
    "    extended_successes_df.loc[name, \"Explained Final MAE (mum)\"] = df.loc[\n",
    "        name, (\"Final MAE (mum)\", \"Explained\", \"Mean\")\n",
    "    ]\n",
    "    extended_successes_df.loc[name, \"Optimisation Normalised MAE improvement (%)\"] = (\n",
    "        df.loc[name, (\"Normalised MAE improvement (%)\", \"Optimsation\", \"Mean\")]\n",
    "    )\n",
    "    extended_successes_df.loc[name, \"Explained Normalised MAE improvement (%)\"] = (\n",
    "        df.loc[name, (\"Normalised MAE improvement (%)\", \"Explained\", \"Mean\")]\n",
    "    )\n",
    "    extended_successes_df.loc[name, \"Optimisation Normalised accumulated MAE (%)\"] = (\n",
    "        df.loc[name, (\"Normalised accumulated MAE (%)\", \"Optimsation\", \"Mean\")]\n",
    "    )\n",
    "    extended_successes_df.loc[name, \"Explained Normalised accumulated MAE (%)\"] = (\n",
    "        df.loc[name, (\"Normalised accumulated MAE (%)\", \"Explained\", \"Mean\")]\n",
    "    )\n",
    "\n",
    "extended_successes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 5, figsize=(6.44, 3), sharex=\"col\", sharey=\"row\")\n",
    "\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"Num parameters\",\n",
    "    y=\"Explained\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    logx=True,\n",
    "    ax=axs[0, 0],\n",
    ")\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"Num parameters\",\n",
    "    y=\"Optimisation\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    logx=True,\n",
    "    ax=axs[0, 0],\n",
    ")\n",
    "axs[0, 0].set_xlabel(None)\n",
    "axs[0, 0].set_ylabel(\"Successful\\nepisodes\")\n",
    "axs[0, 0].set_xscale(\"log\")\n",
    "\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"ELO\",\n",
    "    y=\"Explained\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[0, 1],\n",
    ")\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"ELO\",\n",
    "    y=\"Optimisation\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[0, 1],\n",
    ")\n",
    "axs[0, 1].set_xlabel(None)\n",
    "axs[0, 1].set_ylabel(None)\n",
    "\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"MMLU\",\n",
    "    y=\"Explained\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[0, 2],\n",
    ")\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"MMLU\",\n",
    "    y=\"Optimisation\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[0, 2],\n",
    ")\n",
    "axs[0, 2].set_xlabel(None)\n",
    "axs[0, 2].set_ylabel(None)\n",
    "\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"MT-bench\",\n",
    "    y=\"Explained\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[0, 3],\n",
    ")\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"MT-bench\",\n",
    "    y=\"Optimisation\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[0, 3],\n",
    ")\n",
    "axs[0, 3].set_xlabel(None)\n",
    "axs[0, 3].set_ylabel(None)\n",
    "\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"HellaSwag\",\n",
    "    y=\"Explained\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[0, 4],\n",
    ")\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"HellaSwag\",\n",
    "    y=\"Optimisation\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[0, 4],\n",
    ")\n",
    "axs[0, 4].set_xlabel(None)\n",
    "axs[0, 4].set_ylabel(None)\n",
    "\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"Num parameters\",\n",
    "    y=\"Explained Normalised MAE improvement (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    logx=True,\n",
    "    ax=axs[1, 0],\n",
    ")\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"Num parameters\",\n",
    "    y=\"Optimisation Normalised MAE improvement (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    logx=True,\n",
    "    ax=axs[1, 0],\n",
    ")\n",
    "axs[1, 0].set_xlabel(None)\n",
    "axs[1, 0].set_ylabel(\"Normalised MAE\\nimprovement (\\%)\")\n",
    "axs[1, 0].set_xscale(\"log\")\n",
    "\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"ELO\",\n",
    "    y=\"Explained Normalised MAE improvement (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[1, 1],\n",
    ")\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"ELO\",\n",
    "    y=\"Optimisation Normalised MAE improvement (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[1, 1],\n",
    ")\n",
    "axs[1, 1].set_xlabel(None)\n",
    "axs[1, 1].set_ylabel(None)\n",
    "\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"MMLU\",\n",
    "    y=\"Explained Normalised MAE improvement (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[1, 2],\n",
    ")\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"MMLU\",\n",
    "    y=\"Optimisation Normalised MAE improvement (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[1, 2],\n",
    ")\n",
    "axs[1, 2].set_xlabel(None)\n",
    "axs[1, 2].set_ylabel(None)\n",
    "\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"MT-bench\",\n",
    "    y=\"Explained Normalised MAE improvement (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[1, 3],\n",
    ")\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"MT-bench\",\n",
    "    y=\"Optimisation Normalised MAE improvement (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[1, 3],\n",
    ")\n",
    "axs[1, 3].set_xlabel(None)\n",
    "axs[1, 3].set_ylabel(None)\n",
    "\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"HellaSwag\",\n",
    "    y=\"Explained Normalised MAE improvement (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[1, 4],\n",
    ")\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"HellaSwag\",\n",
    "    y=\"Optimisation Normalised MAE improvement (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[1, 4],\n",
    ")\n",
    "axs[1, 4].set_xlabel(None)\n",
    "axs[1, 4].set_ylabel(None)\n",
    "\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"Num parameters\",\n",
    "    y=\"Explained Normalised accumulated MAE (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    logx=True,\n",
    "    ax=axs[2, 0],\n",
    ")\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"Num parameters\",\n",
    "    y=\"Optimisation Normalised accumulated MAE (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    logx=True,\n",
    "    ax=axs[2, 0],\n",
    ")\n",
    "axs[2, 0].set_xlabel(\"Parameters\")\n",
    "axs[2, 0].set_ylabel(\"Normalised\\naccumulated\\nMAE (\\%)\")\n",
    "axs[2, 0].set_xscale(\"log\")\n",
    "axs[2, 0].set_yscale(\"log\")\n",
    "axs[2, 0].set_ylim(4e1, None)\n",
    "\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"ELO\",\n",
    "    y=\"Explained Normalised accumulated MAE (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[2, 1],\n",
    ")\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"ELO\",\n",
    "    y=\"Optimisation Normalised accumulated MAE (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[2, 1],\n",
    ")\n",
    "axs[2, 1].set_xlabel(\"ELO\")\n",
    "axs[2, 1].set_ylabel(None)\n",
    "axs[2, 1].set_yscale(\"log\")\n",
    "\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"MMLU\",\n",
    "    y=\"Explained Normalised accumulated MAE (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[2, 2],\n",
    ")\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"MMLU\",\n",
    "    y=\"Optimisation Normalised accumulated MAE (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[2, 2],\n",
    ")\n",
    "axs[2, 2].set_xlabel(\"MMLU\")\n",
    "axs[2, 2].set_ylabel(None)\n",
    "axs[2, 2].set_yscale(\"log\")\n",
    "\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"MT-bench\",\n",
    "    y=\"Explained Normalised accumulated MAE (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[2, 3],\n",
    ")\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"MT-bench\",\n",
    "    y=\"Optimisation Normalised accumulated MAE (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[2, 3],\n",
    ")\n",
    "axs[2, 3].set_xlabel(\"MT-bench\")\n",
    "axs[2, 3].set_ylabel(None)\n",
    "axs[2, 3].set_yscale(\"log\")\n",
    "\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"HellaSwag\",\n",
    "    y=\"Explained Normalised accumulated MAE (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[2, 4],\n",
    ")\n",
    "sns.regplot(\n",
    "    data=extended_successes_df,\n",
    "    x=\"HellaSwag\",\n",
    "    y=\"Optimisation Normalised accumulated MAE (%)\",\n",
    "    ci=None,\n",
    "    scatter_kws={\"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    "    ax=axs[2, 4],\n",
    ")\n",
    "axs[2, 4].set_xlabel(\"HellaSwag\")\n",
    "axs[2, 4].set_ylabel(None)\n",
    "axs[2, 4].set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(FIG_DIR / \"correlations.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baselines\")\n",
    "print(\"---------\")\n",
    "for study in baseline_studies:\n",
    "    print(f\"{study.name}: {study.average_inference_times()}\")\n",
    "print(\"\")\n",
    "print(\"Tuning Prompt\")\n",
    "print(\"-------------\")\n",
    "for study in tuning_llm_studies:\n",
    "    print(f\"{study.name}: {study.average_inference_times()}\")\n",
    "print(\"\")\n",
    "print(\"Explained Prompt\")\n",
    "print(\"----------------\")\n",
    "for study in explained_llm_studies:\n",
    "    print(f\"{study.name}: {study.average_inference_times()}\")\n",
    "print(\"\")\n",
    "print(\"Chain-of-thought Prompt\")\n",
    "print(\"-----------------------\")\n",
    "for study in cot_llm_studies:\n",
    "    print(f\"{study.name}: {study.average_inference_times()}\")\n",
    "print(\"\")\n",
    "print(\"Optimisation Prompt\")\n",
    "print(\"-------------------\")\n",
    "for study in optimization_llm_studies:\n",
    "    print(f\"{study.name}: {study.average_inference_times()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_episode = gpt_4_turbo_optimization_study.episodes[1]\n",
    "right_episode = gpt_35_turbo_explained_study.episodes[2]\n",
    "\n",
    "# Plot Layout\n",
    "fig = plt.figure(figsize=(469.7 / 72.72 * 1.24, 5))\n",
    "\n",
    "gs = fig.add_gridspec(1, 1)\n",
    "gs00 = gs[0].subgridspec(4, 3, width_ratios=[0.1, 1, 1], hspace=0.14, wspace=0.075)\n",
    "\n",
    "ax_left_quadrupole = fig.add_subplot(gs00[0, 1])\n",
    "ax_left_steerer = fig.add_subplot(\n",
    "    gs00[1, 1], sharex=ax_left_quadrupole, sharey=ax_left_quadrupole\n",
    ")\n",
    "ax_left_mu = fig.add_subplot(gs00[2, 1], sharex=ax_left_quadrupole)\n",
    "ax_left_sigma = fig.add_subplot(gs00[3, 1], sharex=ax_left_quadrupole)\n",
    "\n",
    "ax_right_quadrupole = fig.add_subplot(gs00[0, 2], sharey=ax_left_quadrupole)\n",
    "ax_right_steerer = fig.add_subplot(\n",
    "    gs00[1, 2], sharex=ax_right_quadrupole, sharey=ax_left_steerer\n",
    ")\n",
    "ax_right_mu = fig.add_subplot(gs00[2, 2], sharex=ax_right_quadrupole, sharey=ax_left_mu)\n",
    "ax_right_sigma = fig.add_subplot(\n",
    "    gs00[3, 2], sharex=ax_right_quadrupole, sharey=ax_left_sigma\n",
    ")\n",
    "\n",
    "ax_dummy1 = fig.add_subplot(gs00[:2, 0])\n",
    "ax_dummy2 = fig.add_subplot(gs00[2:, 0])\n",
    "# ax_dummy1.set_visible(False)\n",
    "for ax in [ax_dummy1, ax_dummy2]:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    [ax.spines[side].set_visible(False) for side in (\"left\", \"top\", \"right\", \"bottom\")]\n",
    "    ax.patch.set_visible(False)\n",
    "\n",
    "for ax in [\n",
    "    ax_left_steerer,\n",
    "    ax_left_quadrupole,\n",
    "    ax_left_mu,\n",
    "    ax_right_steerer,\n",
    "    ax_right_quadrupole,\n",
    "    ax_right_mu,\n",
    "]:\n",
    "    ax.xaxis.set_tick_params(labelbottom=False)\n",
    "for ax in [ax_right_steerer, ax_right_quadrupole, ax_right_mu, ax_right_sigma]:\n",
    "    ax.yaxis.set_tick_params(labelleft=False)\n",
    "\n",
    "#############\n",
    "# Plotting\n",
    "left_episode.plot_quadrupoles(\n",
    "    ax=ax_left_quadrupole, xlabel=False, ylabel=False, legend=False, normalize=True\n",
    ")\n",
    "ax_left_quadrupole.lines[0].set_label(r\"$Q_1$\")\n",
    "ax_left_quadrupole.lines[1].set_label(r\"$Q_2$\")\n",
    "ax_left_quadrupole.lines[2].set_label(r\"$Q_3$\")\n",
    "ax_left_quadrupole.legend(loc=\"upper right\", ncol=3)\n",
    "left_episode.plot_steerers(\n",
    "    ax=ax_left_steerer, xlabel=False, ylabel=False, legend=False, normalize=True\n",
    ")\n",
    "ax_left_steerer.lines[0].set_label(r\"$C_v$\")\n",
    "ax_left_steerer.lines[1].set_label(r\"$C_h$\")\n",
    "ax_left_steerer.legend(loc=\"upper right\", ncol=2)\n",
    "\n",
    "left_episode.plot_beam_parameters(\n",
    "    ax=ax_left_mu, xlabel=False, mode=\"mu\", legend=False, ylabel=False\n",
    ")\n",
    "ax_left_mu.legend(loc=\"upper right\", ncol=2)\n",
    "left_episode.plot_beam_parameters(\n",
    "    ax=ax_left_sigma, xlabel=False, mode=\"sigma\", legend=False, ylabel=False\n",
    ")\n",
    "ax_left_sigma.legend(loc=\"upper right\", ncol=2)\n",
    "\n",
    "right_episode.plot_quadrupoles(\n",
    "    ax=ax_right_quadrupole, xlabel=False, ylabel=False, legend=False, normalize=True\n",
    ")\n",
    "right_episode.plot_steerers(\n",
    "    ax=ax_right_steerer, xlabel=False, ylabel=False, legend=False, normalize=True\n",
    ")\n",
    "\n",
    "right_episode.plot_beam_parameters(\n",
    "    ax=ax_right_mu, xlabel=False, mode=\"mu\", legend=False, ylabel=False\n",
    ")\n",
    "right_episode.plot_beam_parameters(\n",
    "    ax=ax_right_sigma, xlabel=False, mode=\"sigma\", legend=False, ylabel=False\n",
    ")\n",
    "\n",
    "#############\n",
    "# Labels\n",
    "ax_left_sigma.set_xlabel(\"Step\")\n",
    "ax_right_sigma.set_xlabel(\"Step\")\n",
    "ax_dummy1.set_ylabel(\"Normalised actuator setting\")\n",
    "ax_dummy2.set_ylabel(\"Beam parameters (mm)\")\n",
    "ax_left_sigma.set_ylabel(r\"$\\sigma$\")\n",
    "ax_left_mu.set_ylabel(r\"$\\mu$\")\n",
    "ax_left_steerer.set_ylabel(\"Steerers\")\n",
    "ax_left_quadrupole.set_ylabel(\"Quadrupoles\")\n",
    "\n",
    "ax_left_quadrupole.set_title(\"GPT 4 Turbo (Optimisation Prompt)\")\n",
    "ax_right_quadrupole.set_title(\"GPT 3.5 Turbo (Explained Prompt)\")\n",
    "\n",
    "data_axes = [\n",
    "    ax_left_quadrupole,\n",
    "    ax_right_quadrupole,\n",
    "    ax_left_steerer,\n",
    "    ax_right_steerer,\n",
    "    ax_left_mu,\n",
    "    ax_right_mu,\n",
    "    ax_left_sigma,\n",
    "    ax_right_sigma,\n",
    "]\n",
    "bo_axes = [ax_right_quadrupole, ax_right_steerer, ax_right_mu, ax_right_sigma]\n",
    "rl_axes = [ax_left_quadrupole, ax_left_steerer, ax_left_mu, ax_left_sigma]\n",
    "subfig_names = [\"(a)\", \"(b)\", \"(c)\", \"(d)\", \"(e)\", \"(f)\", \"(g)\", \"(h)\"]\n",
    "for idx, ax in enumerate(data_axes):\n",
    "    ax.text(x=0.05, y=0.8, s=subfig_names[idx], transform=ax.transAxes)\n",
    "\n",
    "for ax in [ax_left_sigma, ax_right_sigma]:\n",
    "    ax.set_ylim(None, 5.2)\n",
    "\n",
    "# Fine tuning\n",
    "fig.align_ylabels([ax_left_steerer, ax_left_quadrupole, ax_left_mu, ax_left_sigma])\n",
    "\n",
    "fig.savefig(f\"{FIG_DIR}/example_episodes_combined.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_left_quadrupole.get_yticklabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_left_quadrupole.get_yticks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-accelerator-tuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
